{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas sqlalchemy matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, Store, and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"\\nFiles in this directory:\")\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../vgsales.csv'\n",
    "\n",
    "try:\n",
    "    df_raw = pd.read_csv(data_path)\n",
    "    print(\"Raw data loaded successfully:\")\n",
    "    print(df_raw.head())\n",
    "    \n",
    "    # 2. store data in sqLite\n",
    "    engine = create_engine('sqlite:///vgsales.db', echo=False)\n",
    "    \n",
    "    df_raw.to_sql('sales', con=engine, if_exists='replace', index=False)\n",
    "    \n",
    "    print(\"\\nData successfully saved to 'vgsales.db'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during loading/storing: {e}\")\n",
    "\n",
    "\n",
    "# 3. Load from database and clean\n",
    "try:\n",
    "    engine = create_engine('sqlite:///vgsales.db')\n",
    "    \n",
    "    df = pd.read_sql_table('sales', con=engine)\n",
    "    \n",
    "    # Drop rows where 'Year' is missing\n",
    "    df_cleaned = df.dropna(subset=['Year'])\n",
    "\n",
    "    # Correct data type for 'Year'\n",
    "    df_cleaned['Year'] = df_cleaned['Year'].astype(int)\n",
    "\n",
    "    print(\"\\nCleaned data head:\")\n",
    "    print(df_cleaned.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during cleaning: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar chart - Comparison (Genres)\n",
    "\n",
    "To test our hypothesis that 'Action' and 'Sports' are the top-selling genres in Europe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'Genre' and sum the sales for Europe\n",
    "genre_sales = df_cleaned.groupby('Genre')['EU_Sales'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 5 Genres in Europe (Millions of Sales):\")\n",
    "print(genre_sales.head(5))\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(x=genre_sales.index, y=genre_sales.values, palette='viridis')\n",
    "\n",
    "plt.title('Total European Sales by Genre')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Total Sales (in millions)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal bar chart - Comparison (Platforms)\n",
    "\n",
    "To test my hypothesis that PlayStation platforms are the most dominant in Europe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To group the data by 'Platform' and sum the sales for Europe\n",
    "platform_sales = df_cleaned.groupby('Platform')['EU_Sales'].sum().sort_values(ascending=False)\n",
    "\n",
    "# To display the top 5 as text\n",
    "print(\"Top 5 Platforms in Europe (Millions of Sales):\")\n",
    "print(platform_sales.head(5))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=platform_sales.head(15).values, y=platform_sales.head(15).index, palette='rocket')\n",
    "\n",
    "plt.title('Top 15 Platforms by European Sales')\n",
    "plt.xlabel('Total Sales (in millions)')\n",
    "plt.ylabel('Platform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Plot Graph - Change Over Time\n",
    "\n",
    "To analyse the trend of total video game sales in Europe over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping the data by 'Year' and sum the sales\n",
    "yearly_sales = df_cleaned.groupby('Year')['EU_Sales'].sum()\n",
    "yearly_sales_filtered = yearly_sales[yearly_sales.index > 1990]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=yearly_sales_filtered.index, y=yearly_sales_filtered.values, marker='o')\n",
    "\n",
    "\n",
    "plt.title('Total European Game Sales Per Year (Post-1990)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Sales (in millions)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot - Relationship\n",
    "\n",
    "To analyse if a game's sales in Europe are related to its sales in North America."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Took a random sample of 1000 games\n",
    "df_sample = df_cleaned.sample(n=1000, random_state=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_sample, x='NA_Sales', y='EU_Sales', alpha=0.5)\n",
    "\n",
    "plt.title('Relationship: EU Sales vs. NA Sales (1000 random games)')\n",
    "plt.xlabel('North American Sales (in millions)')\n",
    "plt.ylabel('European Sales (in millions)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion & Analysis\n",
    "\n",
    "My Hypothesis: In Europe, PlayStation platforms have been the most dominant. I also predict that the 'Sports' and 'Action' genres are the highest-selling genres in this region.\n",
    "\n",
    "\n",
    "## Analysis of Results\n",
    "\n",
    "Part 1: Genre Preference (Action & Sports)\n",
    "    First bar chart (\"Total European Sales by Genre\") shows that 'Action' is the #1 highest-selling genre in Europe.\n",
    "    'Sports' is the #2 highest-selling genre.\n",
    "    Conclusion: hypothesis was correct.\n",
    "\n",
    "Part 2: Platform Dominance (PlayStation)\n",
    "     Second bar chart (\"Top 15 Platforms\") shows that the PS2 is the #1 best-selling platform in Europe.\n",
    "     The PS3 is #2.\n",
    "     The PC comes in at #3.\n",
    "     The PS4 is #5.\n",
    "     Conclusion: hypothesis was correct. PlayStation platforms (PS2, PS3, PS4) hold three of the top five spots and are the most dominant platforms in Europe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "\n",
    "To validate my data, I will scrape from Wikipedia list of best-selling game consoles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lxml html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_best-selling_game_consoles\"\n",
    "\n",
    "# kept getting a 403 Forbidden error, wikipedia was blocking python scripts.\n",
    "# added a \"User Agent\" header so the script looks like a web browser.\n",
    "# used headers to disguise script\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "tables = pd.read_html(response.text)\n",
    "df_wiki = tables[0]\n",
    "\n",
    "# wikipedia currently uses 'Platform' instead of 'Console'\n",
    "df_wiki = df_wiki.rename(columns={\n",
    "    'Platform': 'Platform_Name',     # changed from 'Console' to 'Platform'\n",
    "    'Released': 'Release_Year',\n",
    "    'Units sold': 'Global_Sales_Wiki'\n",
    "})\n",
    "\n",
    "print(\"Columns are now:\", df_wiki.columns)\n",
    "print(df_wiki.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_wiki.copy()\n",
    "\n",
    "# cleaning the sales numbers\n",
    "def clean_wiki_numbers(text):\n",
    "    text = str(text)\n",
    "    \n",
    "    \n",
    "    if '[' in text:\n",
    "        text = text.split('[')[0]\n",
    "        \n",
    "    # loop through every character. \n",
    "    # if number (0-9) or a dot (.), keep it. Otherwise, ignore it.\n",
    "    allowed_chars = \"0123456789.\"\n",
    "    clean_text = \"\"\n",
    "    \n",
    "    for char in text:\n",
    "        if char in allowed_chars:\n",
    "            clean_text += char\n",
    "            \n",
    "    return clean_text\n",
    "\n",
    "df_clean['Global_Sales_Wiki'] = df_clean['Global_Sales_Wiki'].apply(clean_wiki_numbers)\n",
    "\n",
    "# to convert to float\n",
    "df_clean['Global_Sales_Wiki'] = pd.to_numeric(df_clean['Global_Sales_Wiki'], errors='coerce')\n",
    "\n",
    "\n",
    "# cleaning platform names\n",
    "name_map = {\n",
    "    'PlayStation 2': 'PS2',\n",
    "    'PlayStation 3': 'PS3',\n",
    "    'PlayStation 4': 'PS4',\n",
    "    'Xbox 360': 'X360',\n",
    "    'Nintendo DS': 'DS',\n",
    "    'Game Boy & Game Boy Color': 'GB',\n",
    "    'Game Boy Advance': 'GBA',\n",
    "    'Nintendo 3DS': '3DS',\n",
    "    'PlayStation': 'PS',\n",
    "    'Xbox': 'XB',\n",
    "    'PlayStation Portable': 'PSP',\n",
    "    'Wii U': 'WiiU',\n",
    "    'Nintendo Switch': 'Switch' \n",
    "}\n",
    "\n",
    "# to clean footnotes from names\n",
    "df_clean['Platform_Name'] = df_clean['Platform_Name'].str.split('[').str[0]\n",
    "df_clean['Platform_Name'] = df_clean['Platform_Name'].str.replace('#', '').str.strip()\n",
    "\n",
    "# renamed using map\n",
    "df_clean['Platform_Name'] = df_clean['Platform_Name'].replace(name_map)\n",
    "\n",
    "print(\"Cleaned Data Sample:\")\n",
    "print(df_clean[['Platform_Name', 'Global_Sales_Wiki']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and Calculating difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped by platform to get one total number per console\n",
    "df_original_sales = df_raw.groupby('Platform')['Global_Sales'].sum().reset_index()\n",
    "\n",
    "# merged two tables together and matched them based on the platform name\n",
    "df_merged = pd.merge(df_original_sales, df_clean, \n",
    "                     left_on='Platform', \n",
    "                     right_on='Platform_Name', \n",
    "                     how='inner') # 'inner' keeps only consoles that exist in both lists\n",
    "\n",
    "# to calculate the difference\n",
    "# wiki sales - original sales = difference\n",
    "df_merged['Difference'] = df_merged['Global_Sales_Wiki'] - df_merged['Global_Sales']\n",
    "\n",
    "print(\"Integration Results (Sorted by Highest Sales):\")\n",
    "print(df_merged[['Platform', 'Global_Sales', 'Global_Sales_Wiki', 'Difference']].sort_values('Global_Sales', ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
